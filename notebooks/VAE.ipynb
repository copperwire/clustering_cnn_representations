{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder\n",
    "\n",
    "The variational autoencoder (VA) is in the class of generative neural networks. Which in contrast to Generative Adverserial Network (GAN) approximates a lower bound on the log-likelihood of the data. \n",
    "\n",
    "Aditionally the VA leverages a encoding scheme that maps the an input, $\\mathcal{X} \\sim P(\\mathcal{X} : \\theta ^*)$, to some lower-dimensional vector space $\\mathcal{z}$. That is we have a set of two non-linear maps $\\phi$ and $\\psi$ where they map to and from the latent space respectively. More formally:\n",
    "\n",
    "$ \\psi: \\mathcal{X} \\rightarrow \\mathcal{z}$ and $\\phi: \\mathcal{z} \\rightarrow \\mathcal{X}$\n",
    "\n",
    "The objective of the VA is to minimize the squared pixel-distance from the reconstructed input, or maximise some MLE for the data. Which is to say the MSE and Binary crossentropy are both valid cost functions. \n",
    "\n",
    "What differentiates a VA from an ordinary autoencoder is the restriction placed on the latent space. One imposes and additional cost forcing the latent variable to a normal, zero mean, unit variance distribution. In practice this is achieved with the addition of a Kullback-Leibler Divergence (KL-divergence) term to the loss function. This divergence is defined as :\n",
    "\n",
    "$D_{KL}(P||Q) = \\int^{\\infty}_{-\\infty} P(x) \\log{\\frac{P(x)}{Q(x)}}dx$\n",
    "\n",
    "The KL-divergence measures the overlap between two distributions and is valued at unity for perfectly overlapping distributions. \n",
    "\n",
    "Of-course this is not an integral (or sum in the discrete case) we want to compute, and it can be  quite easily shown (given some patience and some nicely featured gaussian integrals) that two normal distributions,$P, Q$ , with means $\\mu_1$ and $\\mu_2$, and corresponding standard deviations $\\sigma_1$ and $\\sigma_2$ that the KL-divergence takes the following form \n",
    "\n",
    "$D_{KL}(P||Q) = \\log{\\frac{\\sigma_2}{\\sigma_1}} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2\\sigma_2 ^2} - \\frac{1}{2}$ \n",
    "\n",
    "Which further simplifies when, as in the case for the VA, that $P \\sim \\mathcal{N}(0, 1)$, to \n",
    "\n",
    "$D_{KL}(P||Q) = \\log{\\sigma_2} + \\frac{\\mu_2^2}{2\\sigma_2 ^2} - \\frac{1}{2}$ \n",
    "\n",
    "Traditionally VAs have struggled with problems related to the lower bound approximation and also related to the context-less prediciton of each pixel value. There have been numerous models proposed in remedy to those issues but will not be covered just yet.\n",
    "\n",
    "To summarize  the VA has two parts, the encoder and the decoder as shown in the figures below\n",
    "\n",
    "<img src=\"clustering_cnn_representations/images/encoder.png\" width=\"800\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as ker\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
